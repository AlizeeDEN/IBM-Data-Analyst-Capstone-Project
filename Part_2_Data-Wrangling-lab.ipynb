{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p style=\"text-align:center\">\n",
        "    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork928-2022-01-01\" target=\"_blank\">\n",
        "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
        "    </a>\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Data Wrangling**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hands on Lab\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import pandas module.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the dataset into a dataframe.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h2>Read Data</h2>\n",
        "<p>\n",
        "We utilize the <code>pandas.read_csv()</code> function for reading CSV files. However, in this version of the lab, which operates on JupyterLite, the dataset needs to be downloaded to the interface using the provided code below.\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The functions below will download the dataset into your browser:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from pyodide.http import pyfetch\n",
        "\n",
        "async def download(url, filename):\n",
        "    response = await pyfetch(url)\n",
        "    if response.status == 200:\n",
        "        with open(filename, \"wb\") as f:\n",
        "            f.write(await response.bytes())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "file_path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/LargeData/m1_survey_data.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To obtain the dataset, utilize the download() function as defined above:  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "await download(file_path, \"m1_survey_data.csv\")\n",
        "file_name=\"m1_survey_data.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Utilize the Pandas method read_csv() to load the data into a dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(file_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> Note: This version of the lab is working on JupyterLite, which requires the dataset to be downloaded to the interface.While working on the downloaded version of this notebook on their local machines(Jupyter Anaconda), the learners can simply **skip the steps above,** and simply use the URL directly in the `pandas.read_csv()` function. You can uncomment and run the statements in the cell below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#df = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/LargeData/m1_survey_data.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Finding duplicates\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this section you will identify duplicate values in the dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " Find how many duplicate rows exist in the dataframe.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of duplicate rows in the DataFrame: 154\n"
          ]
        }
      ],
      "source": [
        "num_duplicates = df.duplicated().sum()\n",
        "print(f\"Number of duplicate rows in the DataFrame: {num_duplicates}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of duplicate values in the 'Respondent' column: 154\n"
          ]
        }
      ],
      "source": [
        "# Check for duplicate values in the 'Respondent' column and count them\n",
        "num_duplicates = df['Respondent'].duplicated().sum()\n",
        "\n",
        "print(f\"Number of duplicate values in the 'Respondent' column: {num_duplicates}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Removing duplicates\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Remove the duplicate rows from the dataframe.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df_cleaned = df.drop_duplicates()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Verify if duplicates were actually dropped.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of duplicate rows in the DataFrame: 0\n"
          ]
        }
      ],
      "source": [
        "num_duplicates = df_cleaned.duplicated().sum()\n",
        "print(f\"Number of duplicate rows in the DataFrame: {num_duplicates}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows after removing duplicate rows: 11398\n"
          ]
        }
      ],
      "source": [
        "# Display the number of rows after removing duplicates\n",
        "num_rows_after_deduplication = df_cleaned.shape[0]\n",
        "print(f\"Number of rows after removing duplicate rows: {num_rows_after_deduplication}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Finding Missing values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Find the missing values for all columns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing values per column:\n",
            "Respondent                   0\n",
            "MainBranch                   0\n",
            "Hobbyist                     0\n",
            "OpenSourcer                  0\n",
            "OpenSource                  81\n",
            "Employment                   0\n",
            "Country                      0\n",
            "Student                     51\n",
            "EdLevel                    112\n",
            "UndergradMajor             737\n",
            "EduOther                   164\n",
            "OrgSize                     96\n",
            "DevType                     65\n",
            "YearsCode                    9\n",
            "Age1stCode                  13\n",
            "YearsCodePro                16\n",
            "CareerSat                    0\n",
            "JobSat                       1\n",
            "MgrIdiot                   493\n",
            "MgrMoney                   497\n",
            "MgrWant                    493\n",
            "JobSeek                      0\n",
            "LastHireDate                 0\n",
            "LastInt                    413\n",
            "FizzBuzz                    37\n",
            "JobFactors                   3\n",
            "ResumeUpdate                39\n",
            "CurrencySymbol               0\n",
            "CurrencyDesc                 0\n",
            "CompTotal                  809\n",
            "CompFreq                   206\n",
            "ConvertedComp              816\n",
            "WorkWeekHrs                122\n",
            "WorkPlan                   121\n",
            "WorkChallenge              164\n",
            "WorkRemote                   8\n",
            "WorkLoc                     32\n",
            "ImpSyn                       5\n",
            "CodeRev                      1\n",
            "CodeRevHrs                2426\n",
            "UnitTests                   29\n",
            "PurchaseHow                196\n",
            "PurchaseWhat                38\n",
            "LanguageWorkedWith          11\n",
            "LanguageDesireNextYear     134\n",
            "DatabaseWorkedWith         453\n",
            "DatabaseDesireNextYear    1042\n",
            "PlatformWorkedWith         411\n",
            "PlatformDesireNextYear     544\n",
            "WebFrameWorkedWith        1393\n",
            "WebFrameDesireNextYear    1617\n",
            "MiscTechWorkedWith        2182\n",
            "MiscTechDesireNextYear    1455\n",
            "DevEnviron                  29\n",
            "OpSys                       34\n",
            "Containers                  82\n",
            "BlockchainOrg             2322\n",
            "BlockchainIs              2610\n",
            "BetterLife                  98\n",
            "ITperson                    35\n",
            "OffOn                       38\n",
            "SocialMedia                293\n",
            "Extraversion                20\n",
            "ScreenName                 507\n",
            "SOVisit1st                 325\n",
            "SOVisitFreq                  5\n",
            "SOVisitTo                    1\n",
            "SOFindAnswer                 3\n",
            "SOTimeSaved                 50\n",
            "SOHowMuchTime             1917\n",
            "SOAccount                    1\n",
            "SOPartFreq                1128\n",
            "SOJobs                       6\n",
            "EntTeams                     5\n",
            "SOComm                       0\n",
            "WelcomeChange               85\n",
            "SONewContent              1965\n",
            "Age                        287\n",
            "Gender                      73\n",
            "Trans                      123\n",
            "Sexuality                  542\n",
            "Ethnicity                  675\n",
            "Dependents                 140\n",
            "SurveyLength                19\n",
            "SurveyEase                  14\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "missing_values = df_cleaned.isnull().sum()\n",
        "# Print all the missing values per column\n",
        "pd.set_option('display.max_rows', None)  # Ensure all rows are shown in the output\n",
        "print(\"Missing values per column:\")\n",
        "print(missing_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Find out how many rows are missing in the column 'WorkLoc'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of missing values in 'WorkLoc' column: 32\n"
          ]
        }
      ],
      "source": [
        "missing_workloc = df_cleaned['WorkLoc'].isnull().sum()\n",
        "\n",
        "print(f\"Number of missing values in 'WorkLoc' column: {missing_workloc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imputing missing values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Find the  value counts for the column WorkLoc.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Value counts for the 'WorkLoc' column:\n",
            "Office                                            6806\n",
            "Home                                              3589\n",
            "Other place, such as a coworking space or cafe     971\n",
            "Name: WorkLoc, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "workloc_counts = df_cleaned['WorkLoc'].value_counts()\n",
        "\n",
        "print(\"Value counts for the 'WorkLoc' column:\")\n",
        "print(workloc_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Identify the value that is most frequent (majority) in the WorkLoc column.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The most frequent value in the 'WorkLoc' column is: Office\n"
          ]
        }
      ],
      "source": [
        "# Identify the most frequent value (majority) in the 'WorkLoc' column\n",
        "most_frequent_workloc = workloc_counts.idxmax()\n",
        "\n",
        "print(f\"The most frequent value in the 'WorkLoc' column is: {most_frequent_workloc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Impute (replace) all the empty rows in the column WorkLoc with the value that you have identified as majority.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Impute (replace) empty rows in the 'WorkLoc' column with the most frequent value\n",
        "df['WorkLoc'].fillna('Office', inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After imputation there should ideally not be any empty rows in the WorkLoc column.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Verify if imputing was successful.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of missing values in 'WorkLoc' column after imputation: 32\n"
          ]
        }
      ],
      "source": [
        "# Verify that there are no more missing values in the 'WorkLoc' column\n",
        "missing_workloc_after_imputation = df_cleaned['WorkLoc'].isnull().sum()\n",
        "print(f\"Number of missing values in 'WorkLoc' column after imputation: {missing_workloc_after_imputation}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Normalizing data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are two columns in the dataset that talk about compensation.\n",
        "\n",
        "One is \"CompFreq\". This column shows how often a developer is paid (Yearly, Monthly, Weekly).\n",
        "\n",
        "The other is \"CompTotal\". This column talks about how much the developer is paid per Year, Month, or Week depending upon his/her \"CompFreq\". \n",
        "\n",
        "This makes it difficult to compare the total compensation of the developers.\n",
        "\n",
        "In this section you will create a new column called 'NormalizedAnnualCompensation' which contains the 'Annual Compensation' irrespective of the 'CompFreq'.\n",
        "\n",
        "Once this column is ready, it makes comparison of salaries easy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "List out the various categories in the column 'CompFreq'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Yearly', 'Monthly', 'Weekly'], dtype='object')"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_cleaned.CompFreq.value_counts().index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a new column named 'NormalizedAnnualCompensation'. Use the hint given below if needed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Double click to see the **Hint**.\n",
        "\n",
        "<!--\n",
        "\n",
        "Use the below logic to arrive at the values for the column NormalizedAnnualCompensation.\n",
        "\n",
        "If the CompFreq is Yearly then use the exising value in CompTotal\n",
        "If the CompFreq is Monthly then multiply the value in CompTotal with 12 (months in an year)\n",
        "If the CompFreq is Weekly then multiply the value in CompTotal with 52 (weeks in an year)\n",
        "\n",
        "-->\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-19-3b01fb8a7082>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_cleaned['NormalizedAnnualCompensation'] = df_cleaned['CompTotal']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  CompFreq  CompTotal  NormalizedAnnualCompensation\n",
            "0   Yearly    61000.0                       61000.0\n",
            "1   Yearly   138000.0                      138000.0\n",
            "2   Yearly    90000.0                       90000.0\n",
            "3  Monthly    29000.0                      348000.0\n",
            "4   Yearly    90000.0                       90000.0\n"
          ]
        }
      ],
      "source": [
        "# Create a new column 'NormalizedAnnualCompensation' initialized with the original 'CompTotal' values\n",
        "df_cleaned['NormalizedAnnualCompensation'] = df_cleaned['CompTotal']\n",
        "\n",
        "# Update the new column based on 'CompFreq' values\n",
        "df_cleaned.loc[df_cleaned['CompFreq'] == 'Monthly', 'NormalizedAnnualCompensation'] *= 12\n",
        "df_cleaned.loc[df['CompFreq'] == 'Weekly', 'NormalizedAnnualCompensation'] *= 52\n",
        "\n",
        "# Display the first few rows to verify the new column\n",
        "print(df_cleaned[['CompFreq', 'CompTotal', 'NormalizedAnnualCompensation']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of unique values in the 'CompFreq' column: 3\n"
          ]
        }
      ],
      "source": [
        "# Find the number of unique values in the 'CompFreq' column\n",
        "unique_comp_freq = df_cleaned['CompFreq'].nunique()\n",
        "\n",
        "print(f\"Number of unique values in the 'CompFreq' column: {unique_comp_freq}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of respondents being paid yearly: 6073\n"
          ]
        }
      ],
      "source": [
        "# Filter the DataFrame for respondents being paid yearly\n",
        "yearly_paid_respondents = df_cleaned[df_cleaned['CompFreq'] == 'Yearly']\n",
        "\n",
        "# Count the number of such respondents\n",
        "num_yearly_paid = yearly_paid_respondents.shape[0]\n",
        "\n",
        "print(f\"Number of respondents being paid yearly: {num_yearly_paid}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The median NormalizedAnnualCompensation is: 100000.0\n"
          ]
        }
      ],
      "source": [
        "# Calculate the median of the 'NormalizedAnnualCompensation' column\n",
        "median_normalized_annual_comp = df_cleaned['NormalizedAnnualCompensation'].median()\n",
        "\n",
        "print(f\"The median NormalizedAnnualCompensation is: {median_normalized_annual_comp}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " Copyright Â© 2020 IBM Corporation. This notebook and its source code are released under the terms of the [MIT License](https://cognitiveclass.ai/mit-license?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork928-2022-01-01&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBM-DA0321EN-SkillsNetwork-21426264&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ).\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (Pyodide)",
      "language": "python",
      "name": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "prev_pub_hash": "955deb52b02eec3e16e61df584232f2cc045079d697f475cb65582dbfebe300c"
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
